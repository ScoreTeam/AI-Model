{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess images\n",
    "def process_image(img):\n",
    "\n",
    "    image = cv2.resize(img, (416, 416), interpolation=cv2.INTER_CUBIC)\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255.\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw detected boxes\n",
    "def draw(image, boxes, scores):\n",
    "\n",
    "    for box, score in zip(boxes, scores):\n",
    "        x, y, w, h = box\n",
    "\n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "                \n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.putText(image, '{0} {1:.2f}'.format('person', score),\n",
    "                    (top, left - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (0, 0, 255), 1,\n",
    "                    cv2.LINE_AA)\n",
    "        \n",
    "        cv2.circle(image, (int((top + right) / 2), int((left + bottom) / 2)), radius=0, color=(0, 0, 255), thickness=10)\n",
    "\n",
    "        print('class: {0}, score: {1:.2f}'.format('person', score))\n",
    "        print('box coordinate x,y,w,h: {0}'.format(box))\n",
    "\n",
    "        # add cnn code to distinguish employee form customer\n",
    "        # cropped = image[top:bottom, left:right]\n",
    "        # cv2.imwrite('appearance/detected_'+ str(top) + '_' + str(left) + '_' + str(bottom) + '_' + str(right) +'.png', cropped) # only using the TOP parameter for encoding - later, use another professional way\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance\n",
    "def distance(boxes):\n",
    "    person_location = {}\n",
    "\n",
    "    for i in range(0,len(boxes)):\n",
    "        x, y, w, h = boxes[i]\n",
    "\n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "\n",
    "        centerX = int((top + right) / 2)\n",
    "        centerY = int((left + bottom) / 2)\n",
    "\n",
    "        person_location[\"person\" + \"_\" + str(i)] = centerX,centerY\n",
    "\n",
    "    return person_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# Load the camera matrix and distortion coefficients\n",
    "# with np.load('calib.npz') as X:\n",
    "    # mtx, dist = [X[i] for i in ('mtx', 'dist')]\n",
    "\n",
    "# Define image points and corresponding real-world points\n",
    "def homography(image):\n",
    "image_points = np.array([\n",
    "    # [320, 240],\n",
    "    # [400, 240],\n",
    "    # [320, 320],\n",
    "    # [400, 320]\n",
    "\n",
    "    [0, 0],  # Example points\n",
    "    [image.shape[0], 0],\n",
    "    [0, image.shape[1]],\n",
    "    [image.shape[0], image.shape[1]]\n",
    "], dtype=\"float32\")\n",
    "\n",
    "world_points = np.array([\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1]\n",
    "], dtype=\"float32\")\n",
    "\n",
    "# Compute the homography matrix\n",
    "H, status = cv2.findHomography(image_points, world_points)\n",
    "\n",
    "# Function to transform points using the homography matrix\n",
    "def warp_point(point, H):\n",
    "    point = np.array([point[0], point[1], 1.0]).reshape((3, 1))\n",
    "    warped_point = np.dot(H, point)\n",
    "    warped_point = warped_point / warped_point[2]\n",
    "    return (warped_point[0], warped_point[1])\n",
    "\n",
    "# Example points (centers of bounding boxes)\n",
    "points_to_transform = [\n",
    "    (340, 260),\n",
    "    (360, 260),\n",
    "    # Add more points as needed\n",
    "]\n",
    "\n",
    "# Transform the points\n",
    "transformed_points = [warp_point(pt, H) for pt in points_to_transform]\n",
    "\n",
    "# Calculate the distance between transformed points\n",
    "def calculate_euclidean_distance(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "for i in range(len(transformed_points)):\n",
    "    for j in range(i + 1, len(transformed_points)):\n",
    "        dist = calculate_distance(transformed_points[i], transformed_points[j])\n",
    "        print(f\"Distance between point {i} and point {j}: {dist:.2f} units\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect images\n",
    "def detect_image(image, yolo):\n",
    "    \n",
    "    processed_image = process_image(image)\n",
    "\n",
    "    start = time.time()\n",
    "    boxes, _, scores = yolo.predict(processed_image, image.shape)\n",
    "    end = time.time()\n",
    "\n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "\n",
    "#   explain how print statement works\n",
    "#   {0} indicates that a value will be inserted at this position\n",
    "#   `:.2f` is a format specifier that tells Python to format the value as a floating-point number with 2 decimal places\n",
    "#   `.format(end - start)` This method is used to insert values into the placeholders within a string\n",
    "    \n",
    "    if boxes is not None:\n",
    "        person_location = distance(boxes)\n",
    "        print(person_location)\n",
    "        # draw(image, boxes, scores)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect videos\n",
    "def detect_video(video, yolo):\n",
    "    \n",
    "    # use yolo v3 to detect video.\n",
    "\n",
    "    video_path = os.path.join(\"videos\", \"test\", video)\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # Prepare for saving the detected video\n",
    "    sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n",
    "\n",
    "    \n",
    "    vout = cv2.VideoWriter()\n",
    "    vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n",
    "\n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "\n",
    "        if not res:\n",
    "            break\n",
    "\n",
    "        image = detect_image(frame, yolo)\n",
    "        cv2.imshow(\"detection\", image)\n",
    "\n",
    "        # Save the video frame by frame\n",
    "        vout.write(image)\n",
    "\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "                break\n",
    "\n",
    "    vout.release()\n",
    "    camera.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# import yolo model\n",
    "yolo = YOLO(obj_threshold=0.5, nms_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dataset/0.png\n",
      "(548, 543, 3)\n",
      "data/dataset/1.png\n",
      "(569, 640, 3)\n",
      "data/dataset/2.png\n",
      "(567, 573, 3)\n",
      "data/dataset/3.png\n",
      "(535, 535, 3)\n",
      "data/dataset/4.png\n",
      "(360, 487, 3)\n",
      "data/dataset/5.png\n",
      "(369, 457, 3)\n",
      "data/dataset/6.png\n",
      "(292, 382, 3)\n",
      "data/dataset/7.png\n",
      "(617, 687, 3)\n",
      "data/dataset/8.png\n",
      "(573, 630, 3)\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "for i in range(0,9):\n",
    "    path = 'data/dataset/'+ str(i) +'.png'\n",
    "    print(path)\n",
    "    image = cv2.imread(path)\n",
    "    print(image.shape)\n",
    "    # image = detect_image(image, yolo)\n",
    "    # cv2.imwrite('output/detected_'+ str(i) +'.png', image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
